{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326506a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klemanroy/Downloads/stratus/v2/modeling_v3/script/pyfiles/scrpt2_data_transformation.py:410: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  map_tmoinfo[\"original_column\"].astype(str).str.contains(pattern, na=False),\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Empirical Distribution of Default 90 DPD\n",
      "      default_type90  count       pct\n",
      "0         nondefault    729  0.825595\n",
      "1  default w/in 2yrs     81  0.091733\n",
      "2   default w/in 1yr     43  0.048698\n",
      "3  default w/in 3yrs     25  0.028313\n",
      "4  default w/in 4yrs      5  0.005663\n",
      "\n",
      "\n",
      "Default Definition Counts\n",
      "PD90_1yr\n",
      "nondefault    840\n",
      "default        43\n",
      "Name: count, dtype: int64\n",
      "PD90_2yr\n",
      "nondefault    759\n",
      "default       124\n",
      "Name: count, dtype: int64\n",
      "Nesting violations: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyfiles.scrpt3_data_engineering import *\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,  # PR-AUC\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# XGBoost (optional)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 3\n",
    "THRESH_METHOD = \"f1\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    model_name: str\n",
    "    fold: int\n",
    "    threshold: float\n",
    "    pr_auc: float\n",
    "    roc_auc: float\n",
    "    f1: float\n",
    "    precision: float\n",
    "    recall: float\n",
    "    balanced_acc: float\n",
    "    tn: int\n",
    "    fp: int\n",
    "    fn: int\n",
    "    tp: int\n",
    "\n",
    "\n",
    "def make_y_binary(y_series: pd.Series) -> np.ndarray:\n",
    "    if y_series.dtype == \"O\" or str(y_series.dtype).startswith(\"string\"):\n",
    "        y = y_series.astype(\"string\").str.lower().map({\"default\": 1, \"nondefault\": 0})\n",
    "        if y.isna().any():\n",
    "            bad_vals = y_series[y.isna()].unique()\n",
    "            raise ValueError(f\"Unmapped target values found: {bad_vals}\")\n",
    "        return y.to_numpy(dtype=int)\n",
    "    return y_series.to_numpy(dtype=int)\n",
    "\n",
    "\n",
    "def choose_threshold(y_true: np.ndarray, y_prob: np.ndarray, method: str = \"f1\") -> float:\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_prob)\n",
    "    if thr.size == 0:\n",
    "        return 0.5\n",
    "    if method == \"f1\":\n",
    "        f1_vals = 2 * (prec[:-1] * rec[:-1]) / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "        return float(thr[int(np.nanargmax(f1_vals))])\n",
    "    return 0.5\n",
    "\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_prob: np.ndarray, thr: float):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    pr_auc = float(average_precision_score(y_true, y_prob))\n",
    "    try:\n",
    "        roc_auc = float(roc_auc_score(y_true, y_prob))\n",
    "    except Exception:\n",
    "        roc_auc = float(\"nan\")\n",
    "\n",
    "    f1 = float(f1_score(y_true, y_pred, zero_division=0))\n",
    "    prec = float(precision_score(y_true, y_pred, zero_division=0))\n",
    "    rec = float(recall_score(y_true, y_pred, zero_division=0))\n",
    "    bal_acc = float(balanced_accuracy_score(y_true, y_pred))\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    return pr_auc, roc_auc, f1, prec, rec, bal_acc, int(tn), int(fp), int(fn), int(tp)\n",
    "\n",
    "\n",
    "def undersample_xy(X: np.ndarray, y: np.ndarray, random_state=42) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    idx_pos = np.where(y == 1)[0]\n",
    "    idx_neg = np.where(y == 0)[0]\n",
    "    n = min(len(idx_pos), len(idx_neg))\n",
    "    keep_neg = rng.choice(idx_neg, size=n, replace=False)\n",
    "    keep = np.concatenate([idx_pos, keep_neg])\n",
    "    rng.shuffle(keep)\n",
    "    return X[keep], y[keep]\n",
    "\n",
    "\n",
    "def oversample_xy(X: np.ndarray, y: np.ndarray, random_state=42) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    idx_pos = np.where(y == 1)[0]\n",
    "    idx_neg = np.where(y == 0)[0]\n",
    "    if len(idx_pos) == 0 or len(idx_neg) == 0:\n",
    "        return X, y\n",
    "    if len(idx_pos) < len(idx_neg):\n",
    "        add = rng.choice(idx_pos, size=(len(idx_neg) - len(idx_pos)), replace=True)\n",
    "        keep = np.concatenate([idx_neg, idx_pos, add])\n",
    "    else:\n",
    "        add = rng.choice(idx_neg, size=(len(idx_pos) - len(idx_neg)), replace=True)\n",
    "        keep = np.concatenate([idx_pos, idx_neg, add])\n",
    "    rng.shuffle(keep)\n",
    "    return X[keep], y[keep]\n",
    "\n",
    "\n",
    "def build_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    num_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    cat_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"oh\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_tf, num_cols),\n",
    "            (\"cat\", cat_tf, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "\n",
    "\n",
    "def get_proba(model, X_valid_np) -> np.ndarray:\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X_valid_np)[:, 1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        s = model.decision_function(X_valid_np)\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    raise ValueError(\"Model has neither predict_proba nor decision_function.\")\n",
    "\n",
    "\n",
    "def run_cv_models_no_imblearn(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    id_col: Optional[str] = None,\n",
    "    drop_cols: Optional[List[str]] = None,\n",
    "    out_dir: str = \".\",\n",
    "):\n",
    "    drop_cols = drop_cols or []\n",
    "\n",
    "    df = df.copy()\n",
    "    if id_col is None:\n",
    "        df[\"_row_id\"] = df.index.astype(str)\n",
    "        id_col = \"_row_id\"\n",
    "\n",
    "    y = make_y_binary(df[target_col])\n",
    "    # X = df.drop(columns=[target_col] + drop_cols)\n",
    "\n",
    "    loantape_applicant_cols_short1 = [\"account\", \"brrgy\", \"ctzna\", \"usrsd\", \"vsnla\",  \n",
    "                                     \"cbrr\", \"csgny\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                     \"brrdt\", \"brrtt\", \"brrtb\", \"cbrau_age\", \"cbrra\", \n",
    "                                     \"cbrab\", \"cbrrb\", \"cbrrd\", \"cbrrt\", \"cbrrc\"]\n",
    "    \n",
    "    loantape_applicant_cols_short2 = [\"account\", \"brrgy\", \"ctzna\", \"usrsd\", \"vsnla\",  \n",
    "                                     \"cbrr\", \"csgny\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                     \"brrdt\", \"brrtt\", \"brrtb\", \"cbrra\", \n",
    "                                     \"cbrab\", \"cbrrb\", \"cbrrd\", \"cbrrt\", \"cbrrc\"]\n",
    "    \n",
    "    loantape_applicant_cols_short3 = [\"account\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                     \"brrdt\", \"brrtt\", \"brrtb\"]\n",
    "    \n",
    "    loantape_applicant_cols_short4 = [\"account\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                     \"brrdt\", \"brrtt\", \"brrtb\", \"borrower_fico_dti_interxn\",\n",
    "                                     \"borrower_fico_tliab_interxn\",\n",
    "                                     \"borrower_fico_lasset_interxn\",\n",
    "                                     \"borrower_tliab_to_tincome\",\n",
    "                                     \"borrower_tliab_to_tasset\",\n",
    "                                     \"borrower_lasset_to_tasset\",\n",
    "                                     \"borrower_dti_to_liab\",\n",
    "                                     \"borrower_tliab_to_tassetsLn\",\n",
    "                                     \"borrower_tincome_to_tassetLn\",\n",
    "                                     \"borrower_tliab_to_tincomeLn\"\n",
    "                                    ]\n",
    "    \n",
    "    \n",
    "    X = df[loantape_applicant_cols_short4]\n",
    "\n",
    "    ids = X[id_col].astype(str).to_numpy()\n",
    "    X_model = X.drop(columns=[id_col])\n",
    "\n",
    "    preprocessor = build_preprocessor(X_model)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    fold_results: List[FoldResult] = []\n",
    "    pred_rows = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_model, y), start=1):\n",
    "        X_tr_df, X_va_df = X_model.iloc[tr_idx], X_model.iloc[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "        id_va = ids[va_idx]\n",
    "\n",
    "        # Fit preprocessor on train only, transform both\n",
    "        X_tr_np = preprocessor.fit_transform(X_tr_df)\n",
    "        X_va_np = preprocessor.transform(X_va_df)\n",
    "\n",
    "        # ----- Define estimators per fold -----\n",
    "        estimators = {}\n",
    "\n",
    "        # Logistic baseline\n",
    "        estimators[\"logreg\"] = LogisticRegression(\n",
    "            max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        # Logistic undersample / oversample\n",
    "        estimators[\"logreg_undersample\"] = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
    "        estimators[\"logreg_oversample\"] = LogisticRegression(max_iter=2000, random_state=RANDOM_STATE)\n",
    "\n",
    "        # Decision tree\n",
    "        estimators[\"decision_tree\"] = DecisionTreeClassifier(\n",
    "            max_depth=5, min_samples_leaf=25, class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        # Random forest\n",
    "        estimators[\"random_forest\"] = RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            min_samples_leaf=10,\n",
    "            class_weight=\"balanced_subsample\",\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        # XGBoost\n",
    "        if HAS_XGB:\n",
    "            # scale_pos_weight = neg/pos in the training fold\n",
    "            pos = max(1, int((y_tr == 1).sum()))\n",
    "            neg = max(1, int((y_tr == 0).sum()))\n",
    "            spw = neg / pos\n",
    "            estimators[\"xgboost\"] = XGBClassifier(\n",
    "                n_estimators=600,\n",
    "                max_depth=4,\n",
    "                learning_rate=0.05,\n",
    "                subsample=0.9,\n",
    "                colsample_bytree=0.9,\n",
    "                reg_lambda=1.0,\n",
    "                objective=\"binary:logistic\",\n",
    "                eval_metric=\"logloss\",\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1,\n",
    "                scale_pos_weight=spw\n",
    "            )\n",
    "\n",
    "        # Neural net (MLP) - \"epochs\" analogue: max_iter=10\n",
    "        estimators[\"nn_mlp\"] = MLPClassifier(\n",
    "            hidden_layer_sizes=(64, 32),\n",
    "            activation=\"relu\",\n",
    "            alpha=1e-4,\n",
    "            learning_rate_init=1e-3,\n",
    "            max_iter=10,\n",
    "            early_stopping=False,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        # ----- Fit + Evaluate each -----\n",
    "        for model_name, model in estimators.items():\n",
    "            # sampling for specific variants\n",
    "            if model_name == \"logreg_undersample\":\n",
    "                X_fit, y_fit = undersample_xy(X_tr_np, y_tr, random_state=RANDOM_STATE + fold)\n",
    "            elif model_name == \"logreg_oversample\":\n",
    "                X_fit, y_fit = oversample_xy(X_tr_np, y_tr, random_state=RANDOM_STATE + fold)\n",
    "            else:\n",
    "                X_fit, y_fit = X_tr_np, y_tr\n",
    "\n",
    "            model.fit(X_fit, y_fit)\n",
    "\n",
    "            y_prob = get_proba(model, X_va_np)\n",
    "            thr = choose_threshold(y_va, y_prob, method=THRESH_METHOD)\n",
    "\n",
    "            pr_auc, roc_auc, f1, prec, rec, bal_acc, tn, fp, fn, tp = compute_metrics(y_va, y_prob, thr)\n",
    "            fold_results.append(FoldResult(\n",
    "                model_name=model_name,\n",
    "                fold=fold,\n",
    "                threshold=thr,\n",
    "                pr_auc=pr_auc,\n",
    "                roc_auc=roc_auc,\n",
    "                f1=f1,\n",
    "                precision=prec,\n",
    "                recall=rec,\n",
    "                balanced_acc=bal_acc,\n",
    "                tn=tn, fp=fp, fn=fn, tp=tp\n",
    "            ))\n",
    "\n",
    "            y_pred = (y_prob >= thr).astype(int)\n",
    "            pred_rows.append(pd.DataFrame({\n",
    "                \"row_id\": id_va,\n",
    "                \"model\": model_name,\n",
    "                \"fold\": fold,\n",
    "                \"y_true\": y_va,\n",
    "                \"y_prob\": y_prob,\n",
    "                \"threshold\": thr,\n",
    "                \"y_pred\": y_pred\n",
    "            }))\n",
    "\n",
    "    metrics_df = pd.DataFrame([r.__dict__ for r in fold_results])\n",
    "    preds_df = pd.concat(pred_rows, ignore_index=True)\n",
    "\n",
    "    summary_df = (\n",
    "        metrics_df\n",
    "        .groupby(\"model_name\")[[\"pr_auc\", \"roc_auc\", \"f1\", \"precision\", \"recall\", \"balanced_acc\"]]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "    metrics_path = f\"{out_dir}/cv_metrics_by_fold_{target_col}_4.csv\"\n",
    "    preds_path = f\"{out_dir}/cv_predictions_{target_col}_4.csv\"\n",
    "    summary_path = f\"{out_dir}/cv_metrics_summary_{target_col}_4.csv\"\n",
    "\n",
    "    metrics_df.to_csv(metrics_path, index=False)\n",
    "    preds_df.to_csv(preds_path, index=False)\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "    print(f\"Saved:\\n- {metrics_path}\\n- {summary_path}\\n- {preds_path}\")\n",
    "\n",
    "    return metrics_df, preds_df, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77266c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- ./cv_metrics_by_fold_PD90_2yr_4.csv\n",
      "- ./cv_metrics_summary_PD90_2yr_4.csv\n",
      "- ./cv_predictions_PD90_2yr_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "- ./cv_metrics_by_fold_PD90_1yr_4.csv\n",
      "- ./cv_metrics_summary_PD90_1yr_4.csv\n",
      "- ./cv_predictions_PD90_1yr_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ID_COL = \"account\"  # change if needed\n",
    "\n",
    "DROP_COLS = [\n",
    "    # targets and label helpers\n",
    "    \"PD90_1yr\", \"PD90_2yr\", \"default_type90\", \"default_type120\",\n",
    "    # leakage / timing fields\n",
    "    \"lstdd\", \"lncnt\", \"mtrty\", \"pdffd\",\n",
    "    # add any cutoff-derived fields (days_since_paid, etc.) if present\n",
    "]\n",
    "\n",
    "metrics_2yr, preds_2yr, summary_2yr = run_cv_models_no_imblearn(\n",
    "    df=df_loantape_anly,\n",
    "    target_col=\"PD90_2yr\",\n",
    "    id_col=ID_COL,\n",
    "    drop_cols=DROP_COLS,\n",
    "    out_dir=\".\"\n",
    ")\n",
    "\n",
    "metrics_1yr, preds_1yr, summary_1yr = run_cv_models_no_imblearn(\n",
    "    df=df_loantape_anly,\n",
    "    target_col=\"PD90_1yr\",\n",
    "    id_col=ID_COL,\n",
    "    drop_cols=DROP_COLS,\n",
    "    out_dir=\".\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0828e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fina)",
   "language": "python",
   "name": "fina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
