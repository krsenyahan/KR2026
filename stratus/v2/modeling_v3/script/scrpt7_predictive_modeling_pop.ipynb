{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd20b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyfiles.scrpt3_data_engineering import *\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score,  # PR-AUC\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def label_pop_v1_graduate_to_repay(\n",
    "    df: pd.DataFrame,\n",
    "    cutoff,\n",
    "    *,\n",
    "    graduated_col: str = \"grdtd\",\n",
    "    graduation_date_col: str = \"graduation_date\",\n",
    "    first_payment_date_col: str = \"first_payment_date\",\n",
    "    days_past_due_col: str = \"days_past_due\",   # if missing, you can map to days_late\n",
    "    grace_months: int = 6,\n",
    "    repay_window_months: int = 6,\n",
    "    max_dpd_in_window: int = 30,\n",
    "    treat_N_as_negative: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    PoP v1: Graduate-to-Repay Transition\n",
    "\n",
    "    Goal:\n",
    "      Create an auditable proxy for \"placement\" using only fields you have:\n",
    "      - grdtd (Y/N/NaN)\n",
    "      - graduation_date\n",
    "      - first_payment_date\n",
    "      - days_past_due (or days_late)\n",
    "\n",
    "    Definition (recommended):\n",
    "      - Eligible window begins at graduation_date + grace_months\n",
    "      - Borrower is label-eligible if:\n",
    "          a) grdtd == 'Y' and cutoff >= graduation_date + grace_months + repay_window_months\n",
    "         OR\n",
    "          b) (optional) grdtd == 'N' treated as negative immediately (not censored)\n",
    "      - Placed (PoP=1) if, among eligible:\n",
    "          grdtd == 'Y'\n",
    "          AND first_payment_date <= graduation_date + grace_months\n",
    "          AND days_past_due <= max_dpd_in_window (proxy for \"no early payment failure\")\n",
    "      - Not placed (PoP=0):\n",
    "          grdtd == 'N' (if treat_N_as_negative)\n",
    "          OR grdtd == 'Y' but fails repayment transition condition\n",
    "\n",
    "    Outputs:\n",
    "      Adds columns:\n",
    "        - pop_label_eligible (1/0)\n",
    "        - pop_label (1/0, NaN if not eligible)\n",
    "        - pop_reason (audit trail)\n",
    "\n",
    "    Notes:\n",
    "      - This uses a *single snapshot* `days_past_due` as an approximation of early-window delinquency.\n",
    "        If you later have month-by-month DPD, we can replace this with \"max DPD in months 6–12 post-grad\".\n",
    "    \"\"\"\n",
    "\n",
    "    out = df.copy()\n",
    "    cutoff = pd.Timestamp(cutoff)\n",
    "\n",
    "    # Normalize graduation indicator\n",
    "    grd = out[graduated_col].astype(\"string\").str.upper().str.strip()\n",
    "    grad_date = pd.to_datetime(out[graduation_date_col], errors=\"coerce\")\n",
    "    fpd = pd.to_datetime(out[first_payment_date_col], errors=\"coerce\")\n",
    "\n",
    "    # If days_past_due missing, fallback to days_late if present\n",
    "    if days_past_due_col not in out.columns:\n",
    "        if \"days_late\" in out.columns:\n",
    "            days = pd.to_numeric(out[\"days_late\"], errors=\"coerce\")\n",
    "            used_days_col = \"days_late\"\n",
    "        else:\n",
    "            raise KeyError(f\"Missing `{days_past_due_col}` and no fallback `days_late` found.\")\n",
    "    else:\n",
    "        days = pd.to_numeric(out[days_past_due_col], errors=\"coerce\")\n",
    "        used_days_col = days_past_due_col\n",
    "\n",
    "    # Key dates\n",
    "    grace_end = grad_date + pd.DateOffset(months=grace_months)\n",
    "    window_end = grace_end + pd.DateOffset(months=repay_window_months)\n",
    "\n",
    "    # Eligibility:\n",
    "    # - Graduated AND enough time has passed to observe grace+repay window\n",
    "    eligible_grad = (\n",
    "        (grd == \"Y\") &\n",
    "        grad_date.notna() &\n",
    "        window_end.notna() &\n",
    "        (cutoff >= window_end)\n",
    "    ).fillna(False)\n",
    "\n",
    "    # - Not graduated (N) optionally treated as negative label and eligible immediately\n",
    "    if treat_N_as_negative:\n",
    "        eligible_ng = (grd == \"N\").fillna(False)\n",
    "    else:\n",
    "        eligible_ng = pd.Series(False, index=out.index)\n",
    "\n",
    "    eligible = (eligible_grad | eligible_ng).fillna(False)\n",
    "\n",
    "\n",
    "    # Placement success (for graduated eligibles):\n",
    "    # 1) entered repayment by end of grace\n",
    "    paid_by_grace = (\n",
    "        fpd.notna() &\n",
    "        grace_end.notna() &\n",
    "        (fpd <= grace_end)\n",
    "    ).fillna(False)\n",
    "\n",
    "    stable = (days.fillna(0) <= max_dpd_in_window).fillna(False)\n",
    "\n",
    "    placed = eligible_grad & paid_by_grace & stable\n",
    "\n",
    "    # Negative cases (eligible but not placed)\n",
    "    not_placed = eligible & (~placed)\n",
    "\n",
    "    # Assign label\n",
    "    pop_label = pd.Series(np.nan, index=out.index, dtype=\"float\")\n",
    "    pop_label.loc[placed] = 1.0\n",
    "    pop_label.loc[not_placed] = 0.0\n",
    "\n",
    "    # Audit reason codes\n",
    "    reason = pd.Series(pd.NA, index=out.index, dtype=\"string\")\n",
    "    reason.loc[~eligible] = \"CENSORED_OR_INELIGIBLE\"\n",
    "\n",
    "    reason.loc[eligible_ng] = \"NOT_GRADUATED\"\n",
    "\n",
    "    # For graduated eligibles:\n",
    "    reason.loc[eligible_grad & (~paid_by_grace)] = \"NO_PAYMENT_BY_END_OF_GRACE\"\n",
    "    reason.loc[eligible_grad & paid_by_grace & (~stable)] = f\"EARLY_DELINQUENCY_{used_days_col}_GT_{max_dpd_in_window}\"\n",
    "    reason.loc[placed] = \"PLACED_GRADUATED_AND_REPAYMENT_OK\"\n",
    "\n",
    "    out[\"pop_label_eligible\"] = eligible.astype(int)\n",
    "    out[\"pop_label\"] = pop_label\n",
    "    out[\"pop_reason\"] = reason\n",
    "\n",
    "    # Helpful audit columns\n",
    "    out[\"pop_cutoff\"] = cutoff\n",
    "    out[\"pop_grace_end\"] = grace_end\n",
    "    out[\"pop_window_end\"] = window_end\n",
    "    out[\"pop_paid_by_grace\"] = paid_by_grace.astype(int)\n",
    "    out[\"pop_days_metric_used\"] = used_days_col\n",
    "    out[\"pop_days_metric_value\"] = days\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f810750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop_label_eligible\n",
      "0    756\n",
      "1    127\n",
      "Name: count, dtype: int64\n",
      "pop_label\n",
      "NaN    756\n",
      "0.0     78\n",
      "1.0     49\n",
      "Name: count, dtype: int64\n",
      "pop_reason\n",
      "CENSORED_OR_INELIGIBLE               756\n",
      "NOT_GRADUATED                         52\n",
      "PLACED_GRADUATED_AND_REPAYMENT_OK     49\n",
      "EARLY_DELINQUENCY_dysps_GT_30         26\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "df_loantape_anly = label_pop_v1_graduate_to_repay(\n",
    "    df_loantape_anly,\n",
    "    cutoff=\"2025-12-01\",\n",
    "    graduated_col=\"grdtd\",                 # your field\n",
    "    graduation_date_col=\"grdtn\",\n",
    "    first_payment_date_col=\"fstpy\",\n",
    "    days_past_due_col=\"dysps\",     # or set to \"days_late\" if that’s your available field\n",
    "    grace_months=6,\n",
    "    repay_window_months=6,\n",
    "    max_dpd_in_window=30,\n",
    "    treat_N_as_negative=True\n",
    ")\n",
    "\n",
    "# Sanity checks\n",
    "print(df_loantape_anly[\"pop_label_eligible\"].value_counts(dropna=False))\n",
    "print(df_loantape_anly[\"pop_label\"].value_counts(dropna=False))\n",
    "print(df_loantape_anly[\"pop_reason\"].value_counts(dropna=False).head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c78c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = df_loantape_anly[df_loantape_anly[\"pop_label_eligible\"] == 1].copy()\n",
    "df_pop = df_pop[df_pop[\"pop_label\"].notna()].copy()\n",
    "\n",
    "target_col = \"pop_label\"\n",
    "RANDOM_STATE = 42\n",
    "N_SPLITS = 3\n",
    "THRESH_METHOD = \"accuracy\"\n",
    "\n",
    "y = df_pop[target_col].astype(int).to_numpy()\n",
    "\n",
    "loantape_applicant_cols_short1 = [\"account\", \"brrgy\", \"ctzna\", \"usrsd\", \"vsnla\",  \n",
    "                                    \"cbrr\", \"csgny\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                    \"brrdt\", \"brrtt\", \"brrtb\", \"cbrau_age\", \"cbrra\", \n",
    "                                    \"cbrab\", \"cbrrb\", \"cbrrd\", \"cbrrt\", \"cbrrc\"]\n",
    "\n",
    "loantape_applicant_cols_short2 = [\"account\", \"brrgy\", \"ctzna\", \"usrsd\", \"vsnla\",  \n",
    "                                    \"cbrr\", \"csgny\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                    \"brrdt\", \"brrtt\", \"brrtb\", \"cbrra\", \n",
    "                                    \"cbrab\", \"cbrrb\", \"cbrrd\", \"cbrrt\", \"cbrrc\"]\n",
    "\n",
    "loantape_applicant_cols_short3 = [\"account\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                    \"brrdt\", \"brrtt\", \"brrtb\"]\n",
    "\n",
    "loantape_applicant_cols_short4 = [\"account\", \"brrfc\", \"brrtc\", \"brrta\", \n",
    "                                    \"brrdt\", \"brrtt\", \"brrtb\", \"borrower_fico_dti_interxn\",\n",
    "                                    \"borrower_fico_tliab_interxn\",\n",
    "                                    \"borrower_fico_lasset_interxn\",\n",
    "                                    \"borrower_tliab_to_tincome\",\n",
    "                                    \"borrower_tliab_to_tasset\",\n",
    "                                    \"borrower_lasset_to_tasset\",\n",
    "                                    \"borrower_dti_to_liab\",\n",
    "                                    \"borrower_tliab_to_tassetsLn\",\n",
    "                                    \"borrower_tincome_to_tassetLn\",\n",
    "                                    \"borrower_tliab_to_tincomeLn\"\n",
    "                                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e69a56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_pop(y_true: np.ndarray, y_prob: np.ndarray, thr: float):\n",
    "    y_pred = (y_prob >= thr).astype(int)\n",
    "\n",
    "    pr_auc = float(average_precision_score(y_true, y_prob))\n",
    "    roc_auc = float(roc_auc_score(y_true, y_prob))\n",
    "\n",
    "    precision = float(precision_score(y_true, y_pred, zero_division=0))\n",
    "    recall = float(recall_score(y_true, y_pred, zero_division=0))\n",
    "    f1 = float(f1_score(y_true, y_pred, zero_division=0))\n",
    "    accuracy = float((y_pred == y_true).mean())\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"pr_auc\": pr_auc,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,          # sensitivity\n",
    "        \"specificity\": specificity,\n",
    "        \"f1\": f1,\n",
    "        \"tn\": int(tn),\n",
    "        \"fp\": int(fp),\n",
    "        \"fn\": int(fn),\n",
    "        \"tp\": int(tp),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f1a79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(X: pd.DataFrame) -> ColumnTransformer:\n",
    "    num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    num_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    cat_tf = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"oh\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_tf, num_cols),\n",
    "            (\"cat\", cat_tf, cat_cols),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "\n",
    "def get_proba(model, X_valid_np) -> np.ndarray:\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X_valid_np)[:, 1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        s = model.decision_function(X_valid_np)\n",
    "        return 1 / (1 + np.exp(-s))\n",
    "    raise ValueError(\"Model has neither predict_proba nor decision_function.\")\n",
    "\n",
    "def choose_threshold(y_true: np.ndarray, y_prob: np.ndarray, method: str = \"f1\") -> float:\n",
    "    prec, rec, thr = precision_recall_curve(y_true, y_prob)\n",
    "    if thr.size == 0:\n",
    "        return 0.5\n",
    "    if method == \"f1\":\n",
    "        f1_vals = 2 * (prec[:-1] * rec[:-1]) / (prec[:-1] + rec[:-1] + 1e-12)\n",
    "        return float(thr[int(np.nanargmax(f1_vals))])\n",
    "    return 0.5\n",
    "\n",
    "def run_cv_models_pop(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str = \"pop_label\",\n",
    "    id_col: str = \"account\",\n",
    "    out_dir: str = \".\",\n",
    "):\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1) Restrict to eligible only\n",
    "    # -----------------------------\n",
    "    df = df[df[\"pop_label_eligible\"] == 1].copy()\n",
    "    df = df[df[target_col].notna()].copy()\n",
    "\n",
    "    y = df[target_col].astype(int).to_numpy()\n",
    "\n",
    "    # Feature set (same as applicants)\n",
    "    X = df[loantape_applicant_cols_short4].copy()\n",
    "    ids = X[id_col].astype(str).to_numpy()\n",
    "    X_model = X.drop(columns=[id_col])\n",
    "\n",
    "    preprocessor = build_preprocessor(X_model)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "    fold_rows = []\n",
    "    pred_rows = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_model, y), start=1):\n",
    "        X_tr_df, X_va_df = X_model.iloc[tr_idx], X_model.iloc[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "        id_va = ids[va_idx]\n",
    "\n",
    "        X_tr_np = preprocessor.fit_transform(X_tr_df)\n",
    "        X_va_np = preprocessor.transform(X_va_df)\n",
    "\n",
    "        models = {\n",
    "            \"logreg\": LogisticRegression(\n",
    "                max_iter=2000, class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    "            ),\n",
    "            \"decision_tree\": DecisionTreeClassifier(\n",
    "                max_depth=4, min_samples_leaf=10, class_weight=\"balanced\", random_state=RANDOM_STATE\n",
    "            ),\n",
    "            \"random_forest\": RandomForestClassifier(\n",
    "                n_estimators=300,\n",
    "                min_samples_leaf=10,\n",
    "                class_weight=\"balanced_subsample\",\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_tr_np, y_tr)\n",
    "            y_prob = get_proba(model, X_va_np)\n",
    "            thr = choose_threshold(y_va, y_prob, method=\"f1\")\n",
    "\n",
    "            m = compute_metrics_pop(y_va, y_prob, thr)\n",
    "            m.update({\"model\": name, \"fold\": fold, \"threshold\": thr})\n",
    "            fold_rows.append(m)\n",
    "\n",
    "            pred_rows.append(pd.DataFrame({\n",
    "                \"account\": id_va,\n",
    "                \"model\": name,\n",
    "                \"fold\": fold,\n",
    "                \"y_true\": y_va,\n",
    "                \"y_prob\": y_prob,\n",
    "                \"threshold\": thr,\n",
    "                \"y_pred\": (y_prob >= thr).astype(int)\n",
    "            }))\n",
    "\n",
    "    metrics_df = pd.DataFrame(fold_rows)\n",
    "    preds_df = pd.concat(pred_rows, ignore_index=True)\n",
    "\n",
    "    summary_df = (\n",
    "        metrics_df\n",
    "        .groupby(\"model\")[[\n",
    "            \"accuracy\", \"recall\", \"specificity\",\n",
    "            \"precision\", \"f1\", \"roc_auc\", \"pr_auc\"\n",
    "        ]]\n",
    "        .agg([\"mean\", \"std\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    metrics_df.to_csv(f\"{out_dir}/cv_metrics_by_fold_PoP.csv\", index=False)\n",
    "    preds_df.to_csv(f\"{out_dir}/cv_predictions_PoP.csv\", index=False)\n",
    "    summary_df.to_csv(f\"{out_dir}/cv_metrics_summary_PoP.csv\", index=False)\n",
    "\n",
    "    return metrics_df, preds_df, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ad3fccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "/Users/klemanroy/opt/anaconda3/envs/fina/lib/python3.12/site-packages/sklearn/impute/_base.py:577: UserWarning: Skipping features without any observed values: ['brrtc' 'borrower_fico_lasset_interxn' 'borrower_lasset_to_tasset']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           model  accuracy              recall           specificity  \\\n",
      "                      mean       std      mean       std        mean   \n",
      "0  decision_tree  0.440015  0.102299  0.960784  0.067924    0.115385   \n",
      "1         logreg  0.646364  0.090029  0.856618  0.157832    0.512821   \n",
      "2  random_forest  0.543559  0.157213  0.939951  0.058862    0.294872   \n",
      "\n",
      "            precision                  f1             roc_auc            \\\n",
      "        std      mean       std      mean       std      mean       std   \n",
      "0  0.199852  0.410218  0.050690  0.571898  0.034942  0.577418  0.047883   \n",
      "1  0.225364  0.543979  0.092359  0.653254  0.036216  0.642298  0.055833   \n",
      "2  0.270145  0.469448  0.096497  0.621308  0.081631  0.615196  0.135759   \n",
      "\n",
      "     pr_auc            \n",
      "       mean       std  \n",
      "0  0.449515  0.029285  \n",
      "1  0.514438  0.065112  \n",
      "2  0.503011  0.134649  \n"
     ]
    }
   ],
   "source": [
    "pop_metrics, pop_preds, pop_summary = run_cv_models_pop(\n",
    "    df=df_loantape_anly,\n",
    "    target_col=\"pop_label\",\n",
    "    id_col=\"account\",\n",
    "    out_dir=\".\"\n",
    ")\n",
    "\n",
    "print(pop_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507dd07e",
   "metadata": {},
   "source": [
    "### Calibration of PoP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0909107b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalibration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CalibratedClassifierCV\n\u001b[1;32m      3\u001b[0m cal_pop \u001b[38;5;241m=\u001b[39m CalibratedClassifierCV(\n\u001b[0;32m----> 4\u001b[0m     base_estimator\u001b[38;5;241m=\u001b[39m\u001b[43mlogreg_model\u001b[49m,\n\u001b[1;32m      5\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "cal_pop = CalibratedClassifierCV(\n",
    "    base_estimator=logreg_model,\n",
    "    method=\"sigmoid\",\n",
    "    cv=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b9ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fina)",
   "language": "python",
   "name": "fina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
